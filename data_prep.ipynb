{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# Import required libraries into the project\nimport deeplake\nimport librosa.display\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# load GTZAN dataset\nds = deeplake.load(\"hub://activeloop/gtzan-genre\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Method for converting audio files into melspectrograms for better classification\ndef audio_to_melspectrogram(audio_tensor, sr=22050, n_fft=4096, hop_length=1024, n_mels=256):\n    # convert tensor to numpy array\n    audio_array = audio_tensor.numpy()\n    \n    # compute mel spectrogram\n    mel_spectrogram = librosa.feature.melspectrogram(y=audio_array.squeeze(), sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n    \n    # Convert to decibels\n    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n    \n    return mel_spectrogram_db\n\n# Method for coverting audio files into mfcc spectrograms\ndef audio_to_mfcc(audio_tensor, sr=22050, n_fft=4096, hop_length=1024, n_mfcc=60):\n    # convert tensor to numpy array\n    audio_array = audio_tensor.numpy()\n    \n    # compute mel spectrogram\n    mfcc = librosa.feature.mfcc(y=audio_array.squeeze(), sr=sr, n_fft=n_fft, hop_length=hop_length, n_mfcc=n_mfcc)\n    \n    return mfcc",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Convert the genre tensor into a string (map each category to a string for better reading)\ndef genre_tensor_to_string(genre):\n    # map number to genre name\n    number_genre_map = {0:\"Pop\", 1:\"Metal\", 2:\"Classical\", 3:\"Rock\", 4:\"Blues\", 5:\"Jazz\",\n                        6:\"Hip-hop\", 7:\"Reggae\", 8:\"Disco\", 9:\"Country\"}\n    \n    genre_number = genre.numpy()[0]\n\n    return number_genre_map[genre_number]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Plot the spectrogram for a specific audio file\ndef plot_spectrogram(spectrogram, genre):\n    # display spectrogram\n    plt.figure(figsize=(10, 4))\n    librosa.display.specshow(spectrogram, sr=22050, x_axis='time', y_axis='mel')\n    plt.colorbar(format='%+2.0f dB')\n    plt.title(f'Mel Spectrogram of {genre_tensor_to_string(genre).lower()} song')\n    plt.xlabel('Time (s)')\n    plt.ylabel('Frequency (Hz)')\n    plt.tight_layout()\n    plt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# create list of spectrograms\nspectrograms = []\n\nfor i, audio_tensor in enumerate(ds[\"audio\"]):\n    spectrograms.append(audio_to_melspectrogram(audio_tensor))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# create list of mfcc values for each song\nmfccs = []\n\nfor i, audio_tensor in enumerate(ds[\"audio\"]):\n    mfccs.append(audio_to_mfcc(audio_tensor))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# create list of tuple containing spectrogram and genre\nspectrograms_with_genre = []\ngenre_labels = []\n\nfor i, spectrogram in enumerate(spectrograms):\n    spectrograms_with_genre.append((spectrogram, ds[\"genre\"][i]))\n    genre_labels.append(ds[\"genre\"][i].numpy())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "def pad_numpy_columns(numpy_arrs, target_number=2000):\n    # Pad each spectrogram to have the target number of columns in order to keep data consistent\n    padded_numpy_arrs = []\n    for arr in numpy_arrs:\n        num_columns_to_pad = target_number - arr.shape[1]\n        if num_columns_to_pad > 0:\n            # Pad with zeros to the right (after the spectrogram)\n            padded_arr = np.pad(arr, ((0, 0), (0, num_columns_to_pad)), mode='constant')\n        else:\n            # No padding needed\n            padded_arr = arr\n        padded_numpy_arrs.append(padded_arr)\n    \n    return padded_numpy_arrs",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Pad the spectrograms to have only 1320 columns\npadded_spectrograms = pad_numpy_columns(spectrograms, target_number=1320)\npadded_mfccs = pad_numpy_columns(mfccs, target_number=1320)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "padded_spectrograms[201].shape",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Prepare the spectrograms to run through a KNN algorithm (Abandoned approach)\nspectrograms_flat = [spec.flatten() for spec in padded_spectrograms]\nx1_train, x1_test, y1_train, y1_test = train_test_split(spectrograms_flat, genre_labels, test_size=0.2, random_state=51)\nknn_model_spectrograms = KNeighborsClassifier(n_neighbors=5)\nknn_model_spectrograms.fit(x1_train, y1_train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Prepare the mfcc to run through a KNN algorithm (Abandoned approach)\nmfccs_flat = [mfcc.flatten() for mfcc in padded_mfccs]\nx2_train, x2_test, y2_train, y2_test = train_test_split(mfccs_flat, genre_labels, test_size=0.2, random_state=51)\nknn_model_mfccs = KNeighborsClassifier(n_neighbors=5)\nknn_model_mfccs.fit(x2_train, y2_train)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Evaluate the data from running the KNN algorithm and print the accuracy (For mel spectrograms)\ny1_pred = knn_model_spectrograms.predict(x1_test)\n\naccuracy = accuracy_score(y1_test, y1_pred)\nprint(\"Accuracy: \", accuracy)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Evaluate the data from running the KNN algorithm and print the accuracy (For mfcc)\ny2_pred = knn_model_mfccs.predict(x2_test)\n\naccuracy = accuracy_score(y2_test, y2_pred)\nprint(\"Accuracy: \", accuracy)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# example of plotted spectrogram\n\nplot_spectrogram(spectrograms_with_genre[0][0], spectrograms_with_genre[0][1])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape\nfrom keras.utils import to_categorical",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "padded_spectrograms[0].shape",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Split code into training and testing sets\nx1_train, x1_test, y1_train, y1_test = train_test_split(padded_spectrograms, genre_labels, test_size=0.2, random_state=51)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "y1_train_encoded = to_categorical(y1_train, num_classes=10)  # Assuming you have 10 classes\ny1_test_encoded = to_categorical(y1_test, num_classes=10)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Convert training and testing sets into numpy arrays\nx1_train_array = np.array(x1_train)\nx1_test_array = np.array(x1_test)\ny1_train_encoded_array = np.array(y1_train_encoded)\ny1_test_encoded_array = np.array(y1_test_encoded)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "x1_train_array.shape",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Define the CNN model architecture\n# Define the CNN model architecture\nmodel = Sequential()\nmodel.add(Reshape((256, 1320, 1), input_shape=(256, 1320)))  # Add a channel dimension\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))  # Adjust num_classes according to your task\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(x1_train_array, y1_train_encoded_array, batch_size=32, epochs=10, validation_data=(x1_test_array, y1_test_encoded_array))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}